{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMq1Bmn824K2eeuOjiN8XEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meishihna/GITHUB-COLAB/blob/main/%E6%89%BE%E5%87%BA%E9%95%B7%E7%B4%85K.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**長紅K強勢股**\n",
        "\n",
        "```\n",
        "上傳symbol_pool.csv\n",
        "\n"
      ],
      "metadata": {
        "id": "g2dxn2KLO8AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lineTool\n",
        "!pip install twstock"
      ],
      "metadata": {
        "id": "sJQ5jnsj2p9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import lineTool\n",
        "import twstock\n",
        "import time\n",
        "import csv\n",
        "import os"
      ],
      "metadata": {
        "id": "zxT_B10bOap4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eSy9f-YeNlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498222a7-488d-4a19-f921-d75b3e05e3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date 20240304 file done\n",
            "Date 20240303 no data\n",
            "Date 20240302 no data\n",
            "Date 20240301 file done\n",
            "Date 20240229 file done\n",
            "Date 20240228 no data\n",
            "Date 20240227 file done\n",
            "Date 20240226 file done\n",
            "Date 20240225 no data\n",
            "Date 20240224 no data\n",
            "Date 20240223 file done\n",
            "Date 20240222 file done\n",
            "Date 20240221 file done\n",
            "Date 20240220 file done\n",
            "Date 20240219 file done\n",
            "Date 20240218 no data\n",
            "Date 20240217 no data\n",
            "Date 20240216 file done\n",
            "Date 20240215 file done\n",
            "Date 20240214 no data\n",
            "Date 20240213 no data\n",
            "Date 20240212 no data\n",
            "Date 20240211 no data\n",
            "Date 20240210 no data\n",
            "Date 20240209 no data\n",
            "Date 20240208 no data\n",
            "Date 20240207 no data\n",
            "Date 20240206 no data\n",
            "Date 20240205 file done\n",
            "Date 20240204 no data\n",
            "Date 20240203 no data\n",
            "Date 20240202 file done\n",
            "Date 20240201 file done\n",
            "Date 20240131 file done\n",
            "Date 20240130 file done\n",
            "Date 20240129 file done\n",
            "Date 20240128 no data\n",
            "Date 20240127 no data\n",
            "Date 20240126 file done\n",
            "Date 20240125 file done\n",
            "Date 20240124 file done\n",
            "Date 20240123 file done\n",
            "Date 20240122 file done\n",
            "Date 20240121 no data\n",
            "Date 20240120 no data\n",
            "Date 20240119 file done\n",
            "Date 20240118 file done\n",
            "Date 20240117 file done\n",
            "Date 20240116 file done\n",
            "Date 20240115 file done\n",
            "Date 20240114 no data\n",
            "Date 20240113 no data\n",
            "Date 20240112 file done\n",
            "Date 20240111 file done\n",
            "Date 20240110 file done\n",
            "Date 20240109 file done\n",
            "Date 20240108 file done\n",
            "Date 20240107 no data\n",
            "Date 20240106 no data\n",
            "Date 20240105 file done\n",
            "Date 20240104 file done\n",
            "Date 20240103 file done\n"
          ]
        }
      ],
      "source": [
        "folder_name = \"stock_data\"\n",
        "# 检查文件夹是否存在，如果不存在则创建\n",
        "if not os.path.exists(folder_name):\n",
        "    os.makedirs(folder_name)\n",
        "\n",
        "date_range = [i.strftime('%Y%m%d') for i in pd.date_range('2024-01-01','2024-03-31')]\n",
        "# 因為資料是從最舊的開始抓取，所以將list倒轉\n",
        "date_range.reverse()\n",
        "\n",
        "for d in date_range:\n",
        "    url = 'https://www.twse.com.tw/exchangeReport/MI_INDEX'\n",
        "    formdata = {\n",
        "        'response': 'csv',\n",
        "        'date': d,\n",
        "        'type': 'ALLBUT0999',\n",
        "    }\n",
        "\n",
        "    # 取得資料並且解析\n",
        "    r = requests.get(url, params=formdata)\n",
        "    r.text.encode('utf8')\n",
        "    cr = csv.reader(r.text.splitlines(), delimiter=',')\n",
        "    my_list = list(cr)\n",
        "\n",
        "    # 開始做資料整理\n",
        "    if len(my_list) > 0:\n",
        "        for i in range(len(my_list)):\n",
        "            if len(my_list[i]) > 0:\n",
        "                if my_list[i][0] == '證券代號':\n",
        "                    new_list = my_list[i:]\n",
        "                    break\n",
        "        for j in range(len(new_list)):\n",
        "            if j != 0:\n",
        "                try:\n",
        "                    new_list[j][0] = new_list[j][0].split('\"')[1]\n",
        "                except:\n",
        "                    break\n",
        "        df = pd.DataFrame(new_list[1:], columns=new_list[0])\n",
        "        # TODO 這邊請手動新增資料夾，並將檔案存在指定資料夾內，否則檔案會超多份哦\n",
        "        filename = 'stock_data/price_{}.csv'.format(d)\n",
        "        # 寫入csv\n",
        "        df.to_csv(filename)\n",
        "        print('Date {} file done'.format(d))\n",
        "        time.sleep(3.2)\n",
        "    else:\n",
        "        print('Date {} no data'.format(d))\n",
        "\n",
        "### 從產業分類挑選候選股票清單\n",
        "# symbol_pool = pd.read_csv(\"symbol_pool.csv\", dtype=str)\n",
        "# symbol_list = list(symbol_pool.loc[symbol_pool[\"industry\"].isin([\"金融保險業\"]), \"symbolId\"])\n",
        "\n",
        "### 全選\n",
        "symbol_pool = pd.read_csv(\"symbol_pool.csv\", dtype=str)\n",
        "symbol_list = symbol_pool[\"symbolId\"]\n",
        "## 指定選股資料起訖日期\n",
        "date_from = \"2019-01-01\"\n",
        "date_to = \"2024-12-31\"\n",
        "## 生成交易日曆\n",
        "date_range = pd.date_range(date_from, date_to)\n",
        "date_range_str = [date.strftime(\"%Y%m%d\") for date in date_range]\n",
        "dir_and_files = os.listdir(\"stock_data\")\n",
        "all_open_dates = [\n",
        "    f.split(\"_\")[-1].split(\".\")[0]\n",
        "    for f in dir_and_files\n",
        "    if f[:5] == \"price\" and f[-4:] == \".csv\"\n",
        "]\n",
        "\n",
        "open_dates = [date for date in date_range_str if date in all_open_dates]\n",
        "\n",
        "## 備用資料：讀取並整理資料格式\n",
        "path_price = {date: \"stock_data/price_{}.csv\".format(date) for date in open_dates}\n",
        "price_df = pd.DataFrame()\n",
        "for date in path_price.keys():\n",
        "    one_day_price = pd.read_csv(path_price[date])\n",
        "    one_day_price.index = [date] * len(one_day_price)\n",
        "    price_df = price_df.append(one_day_price.loc[one_day_price[\"證券代號\"].isin(symbol_list)])\n",
        "price_df.index = pd.to_datetime(price_df.index)\n",
        "\n",
        "## 指定邏輯參數\n",
        "vol_ma_p = 20\n",
        "big_vol_multiplier = 2\n",
        "k_body_floor = 0.03\n",
        "k_body_ma_p = 20\n",
        "k_body_multiplier = 2\n",
        "vol_floor = 100\n",
        "\n",
        "price_df[\"開盤價\"] = pd.to_numeric(price_df[\"開盤價\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"收盤價\"] = pd.to_numeric(price_df[\"收盤價\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"最高價\"] = pd.to_numeric(price_df[\"最高價\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"最低價\"] = pd.to_numeric(price_df[\"最低價\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"本益比\"] = pd.to_numeric(price_df[\"本益比\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"成交股數\"] = pd.to_numeric(price_df[\"成交股數\"].str.replace(\"--\",\"\").str.replace(\",\",\"\"))\n",
        "price_df[\"證券代號\"] = pd.to_numeric(price_df[\"證券代號\"])\n",
        "\n",
        "### 從 price_df 萃取出開盤價 DataFrame\n",
        "open_df = price_df.pivot_table(columns = \"證券代號\", index = price_df.index , values = '開盤價' )\n",
        "### 從 price_df 萃取出收盤價 DataFrame\n",
        "close_df = price_df.pivot_table(index=price_df.index, columns=\"證券代號\", values=\"收盤價\")\n",
        "### 從 price_df 萃取出成交量 DataFrame\n",
        "vol_df = price_df.pivot_table(index=price_df.index, columns=\"證券代號\", values=\"成交股數\")\n",
        "\n",
        "### 挑出爆量的股票\n",
        "vol_ma_df = vol_df.rolling(vol_ma_p).mean()\n",
        "big_vol_filter = pd.DataFrame(\n",
        "    np.where(vol_df > vol_ma_df * big_vol_multiplier, True, False),\n",
        "    index=vol_df.index,\n",
        "    columns=vol_df.columns,\n",
        ")\n",
        "\n",
        "### 挑出長紅的股票\n",
        "k_body_range = (close_df - open_df) / open_df  # 正的是紅K、負的是黑K\n",
        "k_body_range_ma = k_body_range.rolling(k_body_ma_p).mean()\n",
        "\n",
        "big_rise_k_filter = pd.DataFrame(\n",
        "    np.where(\n",
        "        (k_body_range > k_body_floor)\n",
        "        & (k_body_range > k_body_range_ma * k_body_multiplier),\n",
        "        True,\n",
        "        False,\n",
        "    ),\n",
        "    index=k_body_range.index,\n",
        "    columns=k_body_range.columns,\n",
        ")\n",
        "\n",
        "### 交易量濾網：捨棄月均量太小的股票\n",
        "avg_vol_df = vol_df.rolling(20).mean()\n",
        "vol_share_floor = vol_floor * 1000\n",
        "vol_filter = pd.DataFrame(np.where(avg_vol_df > vol_share_floor, True, False),\n",
        "    index=avg_vol_df.index,\n",
        "    columns=avg_vol_df.columns,)\n",
        "\n",
        "### 取交集，得到最終結果\n",
        "final_select = big_vol_filter & big_rise_k_filter & vol_filter\n",
        "latest_result = final_select.loc[:, final_select.iloc[-1]].columns\n",
        "\n",
        "def get_two_float(f_str, n):\n",
        "    a, b, c = f_str.partition('.')\n",
        "    c = c[:n]\n",
        "    return \".\".join([a, c])\n",
        "\n",
        "url = \"https://notify-api.line.me/api/notify\"\n",
        "headers = {'Authorization': 'Bearer ' + '0iFwGtNsQXgT0BPCFyI7vqUw1bxGiLsUhl79hXcXVmm'}\n",
        "\n",
        "for code in latest_result:\n",
        "    # 将整数转换为字符串，并添加到stock_codes列表中\n",
        "    stock_codes.append(str(code))\n",
        "\n",
        "messages = {}\n",
        "messages = []\n",
        "for code in latest_result:\n",
        "        try:\n",
        "            stock = twstock.realtime.get(str(code))\n",
        "            if 'info' in stock and 'name' in stock['info'] :\n",
        "                name = stock['info']['name']\n",
        "                data = (f'\\n{code}  【{name}】')\n",
        "                messages.append(data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred: {e}\")\n",
        "            continue\n",
        "    # 合并所有消息\n",
        "combined_message = ''.join(messages)\n",
        "payload = {'message': combined_message}\n",
        "response = requests.post(url, headers=headers, data=payload)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####練習"
      ],
      "metadata": {
        "id": "7UbGBX2lQmES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(\"symbol_pool.csv\")"
      ],
      "metadata": {
        "id": "-gObkz6UQr3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}